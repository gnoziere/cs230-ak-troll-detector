{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Troll Detector Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1fMgEhv1bZrSlP5dkoJuRPWEB2I7ILwP2",
      "authorship_tag": "ABX9TyN5XbiXs16bMUGwRUek658U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1ff57df981545948db6e2cf8e4fc820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04481c67590b40a1a47ac05591d71b9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66ccd1a9ce1b40c58bd506ed0ee5a6ac",
              "IPY_MODEL_40cb4fb018e84ad391ae1079429faec8",
              "IPY_MODEL_03576a7f7e3e45b0a82b30182ed7b1c0"
            ]
          }
        },
        "04481c67590b40a1a47ac05591d71b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66ccd1a9ce1b40c58bd506ed0ee5a6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcb51b64a5ae484db5693156778f9a26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9824584c8b20402eaab60e577a7fa0cf"
          }
        },
        "40cb4fb018e84ad391ae1079429faec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da32df8ac5204ee18a20762b1816223d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 60,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 60,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58cad79cc4de4e418a712cdd07f4bb9c"
          }
        },
        "03576a7f7e3e45b0a82b30182ed7b1c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da09e9f74ebe4d618db65c9bd7463c23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 60.0/60.0 [00:00&lt;00:00, 1.40kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87df2b78d4d54eb4b5f1c4839a6a13d8"
          }
        },
        "dcb51b64a5ae484db5693156778f9a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9824584c8b20402eaab60e577a7fa0cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da32df8ac5204ee18a20762b1816223d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58cad79cc4de4e418a712cdd07f4bb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da09e9f74ebe4d618db65c9bd7463c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87df2b78d4d54eb4b5f1c4839a6a13d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d4fca955d49471a883fd4675cfd5555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b347b957c1b1458ea031e2f48c0a35a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98703e8f5984477299c3497d97a01872",
              "IPY_MODEL_3ccb3edefae04bc3b49a1dfea0c9b4e9",
              "IPY_MODEL_da5cdf056342464491da8391d0f66ebd"
            ]
          }
        },
        "b347b957c1b1458ea031e2f48c0a35a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98703e8f5984477299c3497d97a01872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2193086829d8426e92728e5cbc3c82ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27d96cea06124971b0d839fd29529950"
          }
        },
        "3ccb3edefae04bc3b49a1dfea0c9b4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_802e40366df44fe68618e72561cfe88a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 410,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 410,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d924d953c86343e593c29bb150bd13eb"
          }
        },
        "da5cdf056342464491da8391d0f66ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5abc0243e8db41fbb057f1c4d88cd44e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 410/410 [00:00&lt;00:00, 11.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79a104ed51bc4f1f826e68132af3fae0"
          }
        },
        "2193086829d8426e92728e5cbc3c82ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27d96cea06124971b0d839fd29529950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "802e40366df44fe68618e72561cfe88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d924d953c86343e593c29bb150bd13eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5abc0243e8db41fbb057f1c4d88cd44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79a104ed51bc4f1f826e68132af3fae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4834fe5bed3e43d2852f50b73bf52d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5e160c508844096a3538ba55998c856",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ebe3259d75d74fa48d5aba54f7de2e59",
              "IPY_MODEL_3ef6838e92ab4e83864737a1cc090da8",
              "IPY_MODEL_24426943a2b64b79b4272e808dd9df54"
            ]
          }
        },
        "e5e160c508844096a3538ba55998c856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebe3259d75d74fa48d5aba54f7de2e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91cd62145b5a4a62b6682568b9e877d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19ccaffa642845c6bb6d591ee78d1267"
          }
        },
        "3ef6838e92ab4e83864737a1cc090da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82ef5504124d4999af3feeb12f666e7e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 251003,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 251003,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17d59e030db7455cadaee46fc8e9cb5f"
          }
        },
        "24426943a2b64b79b4272e808dd9df54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60b00d411dbd441e9c968749761a57d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 245k/245k [00:00&lt;00:00, 938kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb0e013a694e482da1f695756ae6b4fb"
          }
        },
        "91cd62145b5a4a62b6682568b9e877d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19ccaffa642845c6bb6d591ee78d1267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82ef5504124d4999af3feeb12f666e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17d59e030db7455cadaee46fc8e9cb5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60b00d411dbd441e9c968749761a57d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb0e013a694e482da1f695756ae6b4fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eff9c29ee45d4a348e234cc2b1a15c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6f4895c5230a4f38a50911e3b73919e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_60386c86c6a44f118e74ceef24a37e5d",
              "IPY_MODEL_030829f122494a3f884620a519c8b1a7",
              "IPY_MODEL_ddbba5e9d0ad4ad1a24947751bca63ac"
            ]
          }
        },
        "6f4895c5230a4f38a50911e3b73919e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60386c86c6a44f118e74ceef24a37e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37a1c922e2fd47889a548145bdb296d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1cd3c3752d0145beb6afb46c45cee8f5"
          }
        },
        "030829f122494a3f884620a519c8b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebfdbab986c94f52886b50a31c88f1e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 272512865,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 272512865,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e512c354852b43c5b9f665f9ab4276ec"
          }
        },
        "ddbba5e9d0ad4ad1a24947751bca63ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5e0e51de88a48ff82f9ca3b4ce0f85d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 260M/260M [00:08&lt;00:00, 28.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdb5fabd05b3400b9e8b3a4bb9878b2a"
          }
        },
        "37a1c922e2fd47889a548145bdb296d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1cd3c3752d0145beb6afb46c45cee8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebfdbab986c94f52886b50a31c88f1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e512c354852b43c5b9f665f9ab4276ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5e0e51de88a48ff82f9ca3b4ce0f85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdb5fabd05b3400b9e8b3a4bb9878b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnoziere/cs230-ak-troll-detector/blob/main/Troll_Detector_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKlQ_HQx3AiV"
      },
      "source": [
        "## Load data from CSV files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTBgS-28lQ5Q",
        "outputId": "527c8cf1-471c-415d-bd19-3ffe09b27002"
      },
      "source": [
        "!pip3 install transformers tweet-preprocessor emoji"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGQyqJMhk3yV"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRGKsjd4G42r"
      },
      "source": [
        "device = \"cuda\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQHcmvtErGIv"
      },
      "source": [
        "# Define paths\n",
        "positive_data_path = \"/content/drive/MyDrive/turkey_052020_tweets_csv_hashed_2011.csv\"\n",
        "negative_data_path = \"/content/drive/MyDrive/turkey_052020_tweets_csv_hashed_2020_01.csv\"\n",
        "model_path = \"dbmdz/distilbert-base-turkish-cased\""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgKY-PJpYEi",
        "outputId": "3d552f78-f2e2-42a6-bf9a-ef2834b695ed"
      },
      "source": [
        "positive_raw_data = pd.read_csv(positive_data_path)\n",
        "positive_raw_data[\"label\"] = 1.0\n",
        "\n",
        "negative_raw_data = pd.read_csv(negative_data_path)\n",
        "negative_raw_data[\"label\"] = 0.0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymst971pvR59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b966c0e9-0b43-44e0-d897-1b169f23f49a"
      },
      "source": [
        "positive_raw_data.columns"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tweetid', 'userid', 'user_display_name', 'user_screen_name',\n",
              "       'user_reported_location', 'user_profile_description',\n",
              "       'user_profile_url', 'follower_count', 'following_count',\n",
              "       'account_creation_date', 'account_language', 'tweet_language',\n",
              "       'tweet_text', 'tweet_time', 'tweet_client_name', 'in_reply_to_userid',\n",
              "       'in_reply_to_tweetid', 'quoted_tweet_tweetid', 'is_retweet',\n",
              "       'retweet_userid', 'retweet_tweetid', 'latitude', 'longitude',\n",
              "       'quote_count', 'reply_count', 'like_count', 'retweet_count', 'hashtags',\n",
              "       'urls', 'user_mentions', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQLVdtccvVkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac9e714-c25b-4a44-9684-3c7dce13222e"
      },
      "source": [
        "positive_raw_data.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35100, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83kdymx27ESK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af019f0f-6153-4ac5-a73e-d553db394ce6"
      },
      "source": [
        "negative_raw_data.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(859516, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiPLKVwR7u1o"
      },
      "source": [
        "merged_data = pd.concat([positive_raw_data, negative_raw_data], ignore_index=True)\n",
        "merged_data = merged_data.sample(frac=1)[:100000]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSalgZU8hto",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c152d7fb-82e6-45c0-cf55-61331e66e272"
      },
      "source": [
        "merged_data.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDYmaLu_3Jql"
      },
      "source": [
        "# Pre-process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc1QFUvR3NuE"
      },
      "source": [
        "merged_data = merged_data.drop([\n",
        "    'latitude', # always 'absent' in positive dataset\n",
        "    'longitude',\n",
        "    'user_profile_url', # always 'NaN in positive dataset\n",
        "    'in_reply_to_userid',\n",
        "    'in_reply_to_tweetid',\n",
        "    'quoted_tweet_tweetid',\n",
        "    'retweet_userid',\n",
        "    'retweet_tweetid',\n",
        "    'quote_count', # can’t access these without a premium developer account\n",
        "    'reply_count' \n",
        "], axis = 1)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QwHAfcm3Nrq",
        "outputId": "857665d1-ed97-4517-cad6-993106ad055d"
      },
      "source": [
        "merged_data.columns"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tweetid', 'userid', 'user_display_name', 'user_screen_name',\n",
              "       'user_reported_location', 'user_profile_description', 'follower_count',\n",
              "       'following_count', 'account_creation_date', 'account_language',\n",
              "       'tweet_language', 'tweet_text', 'tweet_time', 'tweet_client_name',\n",
              "       'is_retweet', 'like_count', 'retweet_count', 'hashtags', 'urls',\n",
              "       'user_mentions', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-iuUuLbe943",
        "outputId": "5c9908d2-221d-4727-eca7-0f114f8ca995"
      },
      "source": [
        "merged_data.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaXqQkyZ3d1B"
      },
      "source": [
        "import preprocessor as p\n",
        "import emoji\n",
        "import string\n",
        "\n",
        "# remove emojis  \n",
        "def remove_emoji(text):\n",
        "    return emoji.get_emoji_regexp().sub(u'', text)\n",
        "\n",
        "# remove url, smiley, hashtag, mention and reserved\n",
        "p.set_options(p.OPT.URL, p.OPT.SMILEY, p.OPT.HASHTAG, p.OPT.MENTION, p.OPT.RESERVED)\n",
        "for i in merged_data.index:\n",
        "  text = merged_data.at[i, 'tweet_text']\n",
        "  text = p.clean(str(text))\n",
        "  text = remove_emoji(text)\n",
        "  text = text.lower().replace('[^\\w\\s]',' ').replace('\\s\\s+', ' ').replace('\\r', ' ').replace('\\n', ' ');\n",
        "  merged_data.at[i, 'tweet_text'] = text\n",
        "\n",
        "  text = merged_data.at[i, 'user_display_name']\n",
        "  text = p.clean(str(text))\n",
        "  text = remove_emoji(text)\n",
        "  text = text.lower().replace('[^\\w\\s]',' ').replace('\\s\\s+', ' ').replace('\\r', ' ').replace('\\n', ' ');\n",
        "  merged_data.at[i, 'user_display_name'] = text\n",
        "\n",
        "  text = merged_data.at[i, 'user_profile_description']\n",
        "  text = p.clean(str(text))\n",
        "  text = remove_emoji(text)\n",
        "  text = text.lower().replace('[^\\w\\s]',' ').replace('\\s\\s+', ' ').replace('\\r', ' ').replace('\\n', ' ');\n",
        "  merged_data.at[i, 'user_profile_description'] = text"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjjXPe0e3u4m"
      },
      "source": [
        "# remove [,], ', NaN from hashtags, urls, and user_mentions\n",
        "merged_data['hashtags'] = merged_data['hashtags'].str.replace('[','').str.replace(']','').str.replace(\"'\",'').str.lower()\n",
        "merged_data['urls'] = merged_data['urls'].str.replace('[','').str.replace(']','').str.replace(\"'\",'')\n",
        "merged_data['user_mentions'] = merged_data['user_mentions'].str.replace('[','').str.replace(']','').str.replace(\"'\",'')\n",
        "\n",
        "merged_data = merged_data.fillna('')"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIKYqfcDgWvU",
        "outputId": "a45a2600-87df-456e-9b57-fb3dafcaa95c"
      },
      "source": [
        "merged_data.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRwRG3vS34RM"
      },
      "source": [
        "# Split sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bzIBqyq0cSp"
      },
      "source": [
        "def split_data(data, train=0.98, test=0.01, eval=0.01):\n",
        "  assert train + test + eval == 1.0\n",
        "\n",
        "  num_examples = data.shape[0]\n",
        "  data = data.sample(frac=1)\n",
        "\n",
        "  train_data = data[:int(num_examples * train)]\n",
        "  test_data = data[int(num_examples * train):int(num_examples * (train+test))]\n",
        "  eval_data = data[int(num_examples * (train+test)):]  # sacred data\n",
        "\n",
        "  return (train_data, test_data, eval_data)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neC_tfes8mt1"
      },
      "source": [
        "train_data, test_data, eval_data = split_data(merged_data, train=0.8, test=0.1, eval=0.1)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn4BTqKwco8e",
        "outputId": "fff9f7e1-6763-4775-c876-442baa78b9b9"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vzn_7pBcqwM",
        "outputId": "89734488-d93f-4880-cb77-0010e18c37a7"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0tEFKpL2IsP",
        "outputId": "9466ad56-091f-4db8-ba5e-debe21eab3ad"
      },
      "source": [
        "eval_data.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIeCNWHpCHvR"
      },
      "source": [
        "# TODO: Transform columns into encodings\n",
        "# TODO: Drop columns we still don't use"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTE7X3RiCBi2",
        "outputId": "6a5ac5f0-73f4-429f-e53f-68bb77f9a93f"
      },
      "source": [
        "train_data.columns  # ground truth columns"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tweetid', 'userid', 'user_display_name', 'user_screen_name',\n",
              "       'user_reported_location', 'user_profile_description', 'follower_count',\n",
              "       'following_count', 'account_creation_date', 'account_language',\n",
              "       'tweet_language', 'tweet_text', 'tweet_time', 'tweet_client_name',\n",
              "       'is_retweet', 'like_count', 'retweet_count', 'hashtags', 'urls',\n",
              "       'user_mentions', 'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paBoEKVY4CuY"
      },
      "source": [
        "# Define features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5BKIuQQxTH9"
      },
      "source": [
        "# Feature info\n",
        "float_features_names = [\n",
        "  \"follower_count\",\n",
        "  \"following_count\",\n",
        "  \"is_retweet\",\n",
        "  \"like_count\",\n",
        "  \"retweet_count\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2yoKeR6q_sy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "a1ff57df981545948db6e2cf8e4fc820",
            "04481c67590b40a1a47ac05591d71b9d",
            "66ccd1a9ce1b40c58bd506ed0ee5a6ac",
            "40cb4fb018e84ad391ae1079429faec8",
            "03576a7f7e3e45b0a82b30182ed7b1c0",
            "dcb51b64a5ae484db5693156778f9a26",
            "9824584c8b20402eaab60e577a7fa0cf",
            "da32df8ac5204ee18a20762b1816223d",
            "58cad79cc4de4e418a712cdd07f4bb9c",
            "da09e9f74ebe4d618db65c9bd7463c23",
            "87df2b78d4d54eb4b5f1c4839a6a13d8",
            "4d4fca955d49471a883fd4675cfd5555",
            "b347b957c1b1458ea031e2f48c0a35a0",
            "98703e8f5984477299c3497d97a01872",
            "3ccb3edefae04bc3b49a1dfea0c9b4e9",
            "da5cdf056342464491da8391d0f66ebd",
            "2193086829d8426e92728e5cbc3c82ba",
            "27d96cea06124971b0d839fd29529950",
            "802e40366df44fe68618e72561cfe88a",
            "d924d953c86343e593c29bb150bd13eb",
            "5abc0243e8db41fbb057f1c4d88cd44e",
            "79a104ed51bc4f1f826e68132af3fae0",
            "4834fe5bed3e43d2852f50b73bf52d3f",
            "e5e160c508844096a3538ba55998c856",
            "ebe3259d75d74fa48d5aba54f7de2e59",
            "3ef6838e92ab4e83864737a1cc090da8",
            "24426943a2b64b79b4272e808dd9df54",
            "91cd62145b5a4a62b6682568b9e877d8",
            "19ccaffa642845c6bb6d591ee78d1267",
            "82ef5504124d4999af3feeb12f666e7e",
            "17d59e030db7455cadaee46fc8e9cb5f",
            "60b00d411dbd441e9c968749761a57d0",
            "cb0e013a694e482da1f695756ae6b4fb"
          ]
        },
        "outputId": "7f5f0b28-fdb6-436d-c55c-384e933aab33"
      },
      "source": [
        "# Data pre-processing\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1ff57df981545948db6e2cf8e4fc820",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d4fca955d49471a883fd4675cfd5555",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/410 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4834fe5bed3e43d2852f50b73bf52d3f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/245k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcEVReFFEyns"
      },
      "source": [
        "# Define model steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJh49_Sa9GXk"
      },
      "source": [
        "def process_data(batch):\n",
        "  feature_dict = tokenizer(\n",
        "      batch[\"tweet_text\"].tolist(),\n",
        "      padding=True,\n",
        "      truncation=True,\n",
        "      return_tensors=\"pt\",\n",
        "  )\n",
        "\n",
        "  numerical_data = batch[float_features_names].astype(float)\n",
        "  feature_dict[\"float_features\"] = torch.from_numpy(numerical_data.values).float()\n",
        "\n",
        "  labels = batch[\"label\"].astype(float)\n",
        "  feature_dict[\"labels\"] = torch.from_numpy(labels.values).float()\n",
        "\n",
        "  return feature_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Igkg-Lka1-"
      },
      "source": [
        "# class BertTweetClassifier(nn.Module):\n",
        "#   def __init__(self, hidden_size, dense_size, numeric_feature_size, output_size, dropout=0.1):\n",
        "#     super().__init__()\n",
        "#     self.hidden_size = hidden_size\n",
        "#     self.output_size = output_size\n",
        "\n",
        "#     # Use pre-trained BERT model\n",
        "#     self.bert = AutoModel.from_pretrained(\n",
        "#         model_path,\n",
        "#         output_hidden_states=True,\n",
        "#         output_attentions=True,\n",
        "#     )\n",
        "\n",
        "#     for param in self.bert.parameters():\n",
        "#         param.requires_grad = False  # No backprop here for now\n",
        "\n",
        "#     self.weights = nn.Parameter(torch.rand(13, 1))\n",
        "#     self.dropout = nn.Dropout(dropout)\n",
        "#     self.fc1 = nn.Linear(hidden_size, dense_size)\n",
        "#     self.fc2 = nn.Linear(dense_size + numeric_feature_size, output_size)\n",
        "#     self.relu = nn.ReLU()\n",
        "#     self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "#   def forward(self, feature_dict):\n",
        "#     times = []\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     input_ids = feature_dict[\"input_ids\"]\n",
        "#     float_features = feature_dict[\"float_features\"]\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     all_hidden_states, all_attentions = self.bert(input_ids)[-2:]\n",
        "#     batch_size = input_ids.shape[0]\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     ht_cls = torch.cat(all_hidden_states)[:, :1, :].view(13, batch_size, 1, self.hidden_size)\n",
        "#     atten = torch.sum(ht_cls * self.weights.view(13, 1, 1, 1), dim=[1, 3])\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     atten = F.softmax(atten.view(-1), dim=0)\n",
        "#     feature = torch.sum(ht_cls * atten.view(13, 1, 1, 1), dim=[0, 2])\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     dense_out = self.fc1(self.dropout(feature))\n",
        "#     activ_out = self.relu(dense_out)\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     concat_layer = torch.cat((activ_out, float_features), 1)\n",
        "#     out = self.fc2(concat_layer)\n",
        "#     prediction = self.sigmoid(out)\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     print(times)\n",
        "\n",
        "#     return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TA33xO7xEIT"
      },
      "source": [
        "# class BertTweetClassifier(nn.Module):\n",
        "#   def __init__(self, hidden_size, dense_size, numeric_feature_size, output_size, dropout=0.1):\n",
        "#     super().__init__()\n",
        "#     self.hidden_size = hidden_size\n",
        "#     self.output_size = output_size\n",
        "\n",
        "#     # Use pre-trained BERT model\n",
        "#     self.bert = AutoModel.from_pretrained(\n",
        "#         model_path,\n",
        "#         output_hidden_states=True,\n",
        "#         output_attentions=True,\n",
        "#     )\n",
        "\n",
        "#     for param in self.bert.parameters():\n",
        "#         param.requires_grad = False  # No backprop here for now\n",
        "\n",
        "#     self.weights = nn.Parameter(torch.rand(7, 1))\n",
        "#     self.dropout = nn.Dropout(dropout)\n",
        "#     self.fc1 = nn.Linear(hidden_size, dense_size)\n",
        "#     self.fc2 = nn.Linear(dense_size + numeric_feature_size, output_size)\n",
        "#     self.relu = nn.ReLU()\n",
        "#     self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "#   def forward(self, feature_dict):\n",
        "#     times = []\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     input_ids = feature_dict[\"input_ids\"]\n",
        "#     float_features = feature_dict[\"float_features\"]\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     all_hidden_states, all_attentions = self.bert(input_ids, output_attentions=True, output_hidden_states=True)[-2:]\n",
        "#     batch_size = input_ids.shape[0]\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     ht_cls = torch.cat(all_hidden_states)[:, :1, :].view(7, batch_size, 1, self.hidden_size)\n",
        "#     atten = torch.sum(ht_cls * self.weights.view(7, 1, 1, 1), dim=[1, 3])\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     atten = F.softmax(atten.view(-1), dim=0)\n",
        "#     feature = torch.sum(ht_cls * atten.view(7, 1, 1, 1), dim=[0, 2])\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     dense_out = self.fc1(self.dropout(feature))\n",
        "#     activ_out = self.relu(dense_out)\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     concat_layer = torch.cat((activ_out, float_features), 1)\n",
        "#     out = self.fc2(concat_layer)\n",
        "#     prediction = self.sigmoid(out)\n",
        "\n",
        "#     torch.cuda.synchronize()\n",
        "#     times.append(time.time() - t0)\n",
        "\n",
        "#     print(times)\n",
        "\n",
        "#     return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z1i5D2i506F"
      },
      "source": [
        "class BertTweetClassifier(nn.Module):\n",
        "  def __init__(self, hidden_size, dense_size, numeric_feature_size, output_size, dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Use pre-trained BERT model\n",
        "    self.bert = AutoModel.from_pretrained(\n",
        "        model_path,\n",
        "        output_hidden_states=True,\n",
        "        output_attentions=True,\n",
        "    )\n",
        "\n",
        "    for param in self.bert.parameters():\n",
        "        param.requires_grad = False  # No backprop here for now\n",
        "\n",
        "    self.weights = nn.Parameter(torch.rand(7, 1))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc1 = nn.Linear(hidden_size, dense_size)\n",
        "    self.fc2 = nn.Linear(dense_size + numeric_feature_size, output_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, feature_dict):\n",
        "    input_ids = feature_dict[\"input_ids\"]\n",
        "    float_features = feature_dict[\"float_features\"]\n",
        "\n",
        "    all_hidden_states, all_attentions = self.bert(input_ids, output_attentions=True, output_hidden_states=True)[-2:]\n",
        "    batch_size = input_ids.shape[0]\n",
        "\n",
        "    ht_cls = torch.cat(all_hidden_states)[:, :1, :].view(7, batch_size, 1, self.hidden_size)\n",
        "    atten = torch.sum(ht_cls * self.weights.view(7, 1, 1, 1), dim=[1, 3])\n",
        "\n",
        "    atten = F.softmax(atten.view(-1), dim=0)\n",
        "    feature = torch.sum(ht_cls * atten.view(7, 1, 1, 1), dim=[0, 2])\n",
        "\n",
        "    dense_out = self.fc1(self.dropout(feature))\n",
        "    activ_out = self.relu(dense_out)\n",
        "\n",
        "    concat_layer = torch.cat((activ_out, float_features), 1)\n",
        "    out = self.fc2(concat_layer)\n",
        "    prediction = self.sigmoid(out)\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlCOsVeJzOD5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "referenced_widgets": [
            "eff9c29ee45d4a348e234cc2b1a15c71",
            "6f4895c5230a4f38a50911e3b73919e9",
            "60386c86c6a44f118e74ceef24a37e5d",
            "030829f122494a3f884620a519c8b1a7",
            "ddbba5e9d0ad4ad1a24947751bca63ac",
            "37a1c922e2fd47889a548145bdb296d1",
            "1cd3c3752d0145beb6afb46c45cee8f5",
            "ebfdbab986c94f52886b50a31c88f1e6",
            "e512c354852b43c5b9f665f9ab4276ec",
            "e5e0e51de88a48ff82f9ca3b4ce0f85d",
            "cdb5fabd05b3400b9e8b3a4bb9878b2a"
          ]
        },
        "outputId": "fa818ebc-a5c2-499c-f157-d6b8960611d6"
      },
      "source": [
        "model = BertTweetClassifier(768, 32, 5, 1).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eff9c29ee45d4a348e234cc2b1a15c71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/260M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/distilbert-base-turkish-cased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wmkZR2w0hZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c3a5aa-82f2-44e5-ae6f-763bfc8e3828"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTweetClassifier(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=768, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=37, out_features=1, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O28KzuuzE4xm"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8AHhmfY5CgE"
      },
      "source": [
        "# for epoch_num in range(num_epochs):\n",
        "#   train_data = train_data.sample(frac=1)  # Shuffle the batches each epoch\n",
        "#   for batch_num in range(0, num_examples, batch_size):\n",
        "#     batch_data = train_data[batch_num : min(batch_num + batch_size, num_examples)]\n",
        "#     feature_dict = process_data(batch_data)\n",
        "#     predictions = np.squeeze(model(feature_dict))\n",
        "#     labels = feature_dict[\"labels\"]\n",
        "#     loss = criterion(predictions, labels)\n",
        "#     print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3NHu75mM3B0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acbbd06-b16c-4212-d75c-5958f7d9fd62"
      },
      "source": [
        "import time\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "567"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0y6-sa4FChp"
      },
      "source": [
        "def report_eval_metrics(model, test_data, batch_size=256):\n",
        "  num_examples = test_data.shape[0]\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  model.zero_grad()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_start_index in range(0, num_examples, batch_size):\n",
        "      batch_num = int(batch_start_index / batch_size)\n",
        "      if batch_num % 100 == 0:\n",
        "        print(f\"Batch {batch_num} started\")\n",
        "\n",
        "      batch_data = test_data[batch_num : min(batch_num + batch_size, num_examples)]\n",
        "\n",
        "      feature_dict = process_data(batch_data).to(device)\n",
        "      predictions = np.squeeze(model(feature_dict))  ## TODO: Speed up\n",
        "      labels = feature_dict[\"labels\"]\n",
        "\n",
        "      loss = criterion(predictions, labels)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      del predictions\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  return total_loss / num_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "HRNm3Cd6Fezz",
        "outputId": "f8f1912e-fc7b-4717-8128-1c14f1a30efe"
      },
      "source": [
        "report_eval_metrics(model, test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 started\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-9260cf6309b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreport_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-757d4b54b308>\u001b[0m in \u001b[0;36mreport_eval_metrics\u001b[0;34m(model, test_data, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mfeature_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## TODO: Speed up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-9729a8d20342>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feature_dict)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfloat_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"float_features\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mall_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             )\n\u001b[1;32m    330\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         )\n\u001b[1;32m    279\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, q_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, q_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 238.00 MiB (GPU 0; 11.17 GiB total capacity; 10.40 GiB already allocated; 161.81 MiB free; 10.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgXb9qgm0bmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a91fa35-6dce-4772-d33b-3e18fdbe8b07"
      },
      "source": [
        "batch_size = 64\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 3\n",
        "num_examples = train_data.shape[0]\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "model.zero_grad()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "batch_count = math.ceil(num_examples / batch_size)\n",
        "\n",
        "for epoch_num in range(num_epochs):\n",
        "  print(f\"Epoch {epoch_num} started\")\n",
        "  train_data = train_data.sample(frac=1)  # Shuffle the batches each epoch\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  ### 0.4 seconds total per loop ###\n",
        "  for batch_start_index in range(0, num_examples, batch_size):\n",
        "    model.zero_grad()\n",
        "\n",
        "    batch_num = int(batch_start_index / batch_size)\n",
        "    if batch_num % 100 == 0:\n",
        "      print(f\"Batch {batch_num} started\")\n",
        "\n",
        "    batch_data = train_data[batch_num : min(batch_num + batch_size, num_examples)]\n",
        "\n",
        "    feature_dict = process_data(batch_data).to(device)\n",
        "    predictions = np.squeeze(model(feature_dict))  ## TODO: Speed up\n",
        "    labels = feature_dict[\"labels\"]\n",
        "\n",
        "    loss = criterion(predictions, labels)\n",
        "    total_epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    ### 0.1 seconds start ###\n",
        "    del predictions\n",
        "    torch.cuda.empty_cache()\n",
        "    ### 0.1 seconds end ###\n",
        "\n",
        "  print(f\"Epoch {epoch_num} finished\")\n",
        "  print(\"Average batch loss: \" + str(total_epoch_loss / batch_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 0 finished\n",
            "Average batch loss: 3.007789291671845\n",
            "Epoch 1 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 1 finished\n",
            "Average batch loss: 3.158608843241777\n",
            "Epoch 2 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 2 finished\n",
            "Average batch loss: 3.4898591280646025\n",
            "Epoch 3 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 3 finished\n",
            "Average batch loss: 3.1809251138435344\n",
            "Epoch 4 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 4 finished\n",
            "Average batch loss: 2.6406766729768187\n",
            "Epoch 5 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 5 finished\n",
            "Average batch loss: 2.9168814668975847\n",
            "Epoch 6 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 6 finished\n",
            "Average batch loss: 2.360993520541312\n",
            "Epoch 7 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 7 finished\n",
            "Average batch loss: 3.315167412330942\n",
            "Epoch 8 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n",
            "Batch 200 started\n",
            "Batch 300 started\n",
            "Batch 400 started\n",
            "Batch 500 started\n",
            "Batch 600 started\n",
            "Batch 700 started\n",
            "Epoch 8 finished\n",
            "Average batch loss: 3.3316634444934032\n",
            "Epoch 9 started\n",
            "Batch 0 started\n",
            "Batch 100 started\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5_bA5jiHE1U"
      },
      "source": [
        "# Saving objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cytOe59HIO_"
      },
      "source": [
        "train_data_path = \"/content/drive/MyDrive/train_data.zip\"\n",
        "test_data_path = \"/content/drive/MyDrive/test_data.zip\"\n",
        "eval_data_path = \"/content/drive/MyDrive/eval_data.zip\""
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUoAkyMzHIMI"
      },
      "source": [
        "train_data.to_csv(path_or_buf=train_data_path, index=False)\n",
        "test_data.to_csv(path_or_buf=test_data_path, index=False)\n",
        "eval_data.to_csv(path_or_buf=eval_data_path, index=False)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKNezVi5Iit6"
      },
      "source": [
        "test_read = pd.read_csv(train_data_path)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZlxLw6wIvdT",
        "outputId": "09d048f9-6985-46c1-c983-99dd162b8f4e"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXPiOD-PIpzW",
        "outputId": "1ea4fc36-d9b3-4f56-a6d1-55fa7604b95c"
      },
      "source": [
        "test_read.shape"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOSJwXTgNC3k",
        "outputId": "b2cb689b-14e6-448d-c9ba-4d3ac608a658"
      },
      "source": [
        "train_data.iloc[8169]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweetid                                                   1217514045751930882\n",
              "userid                            vzE2Thz2OP5EUbQsVtqv90Ri7KiFTUHafGgb+aJxag=\n",
              "user_display_name                 vze2thz2op5eubqsvtqv90ri7kiftuhafggb+ajxag=\n",
              "user_screen_name                  vzE2Thz2OP5EUbQsVtqv90Ri7KiFTUHafGgb+aJxag=\n",
              "user_reported_location                                                       \n",
              "user_profile_description                                                  nan\n",
              "follower_count                                                            528\n",
              "following_count                                                          1106\n",
              "account_creation_date                                              2016-02-20\n",
              "account_language                                                           tr\n",
              "tweet_language                                                             tr\n",
              "tweet_text                  : hiçbir esnaf ticari itibarını i̇smini çocuğu...\n",
              "tweet_time                                                   2020-01-15 18:29\n",
              "tweet_client_name                                          Twitter for iPhone\n",
              "is_retweet                                                               True\n",
              "like_count                                                                  0\n",
              "retweet_count                                                               0\n",
              "hashtags                                                                     \n",
              "urls                                                                         \n",
              "user_mentions                                                       352297559\n",
              "label                                                                       0\n",
              "Name: 389860, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAjKPtvfNC06",
        "outputId": "e20627a9-6efb-4695-8427-effeccc2bacc"
      },
      "source": [
        "test_read['tweetid'].iloc[8169]"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1217514045751930882"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "c19YCVR2L0vy",
        "outputId": "e7a99d45-8a28-4c3d-9df3-ea6933cd9569"
      },
      "source": [
        "i = 0\n",
        "j = 0\n",
        "bad_j_vals = []\n",
        "\n",
        "while (i < train_data.shape[0]):\n",
        "  if str(train_data['tweetid'].iat[i]) != test_read['tweetid'].iat[j]:\n",
        "    bad_j_vals.append(j)\n",
        "    j += 1\n",
        "  else:\n",
        "    i += 1\n",
        "    j += 1\n",
        "\n",
        "bad_j_vals"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-eac1aef5dc1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweetid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_read\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweetid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbad_j_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2025\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \"\"\"\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 80000 is out of bounds for axis 0 with size 80000"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HZ8L8Z2Env9"
      },
      "source": [
        "# Debugging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVjsY7_kErGm"
      },
      "source": [
        "times"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "ltvwfZFyALHz",
        "outputId": "75658e1b-0160-432c-caa4-cf8ace18e8b7"
      },
      "source": [
        "torch.cuda.memory_summary(device=\"cuda\", abbreviated=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 8            |        cudaMalloc retries: 13        |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   10661 MB |   10674 MB |   10036 GB |   10026 GB |\\n|       from large pool |   10658 MB |   10672 MB |   10032 GB |   10021 GB |\\n|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   10661 MB |   10674 MB |   10036 GB |   10026 GB |\\n|       from large pool |   10658 MB |   10672 MB |   10032 GB |   10021 GB |\\n|       from small pool |       2 MB |       3 MB |       4 GB |       4 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   10854 MB |   10854 MB |   51088 MB |   40234 MB |\\n|       from large pool |   10850 MB |   10850 MB |   51084 MB |   40234 MB |\\n|       from small pool |       4 MB |       4 MB |       4 MB |       0 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |  197357 KB |    3238 MB |    8339 GB |    8339 GB |\\n|       from large pool |  196048 KB |    3236 MB |    8333 GB |    8333 GB |\\n|       from small pool |    1309 KB |       2 MB |       6 GB |       6 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     516    |     520    |  603801    |  603285    |\\n|       from large pool |     218    |     222    |  431584    |  431366    |\\n|       from small pool |     298    |     313    |  172217    |  171919    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     516    |     520    |  603801    |  603285    |\\n|       from large pool |     218    |     222    |  431584    |  431366    |\\n|       from small pool |     298    |     313    |  172217    |  171919    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      69    |     100    |     241    |     172    |\\n|       from large pool |      67    |      98    |     239    |     172    |\\n|       from small pool |       2    |       2    |       2    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      71    |      77    |  307808    |  307737    |\\n|       from large pool |      59    |      67    |  247619    |  247560    |\\n|       from small pool |      12    |      16    |   60189    |   60177    |\\n|===========================================================================|\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIef9DSDQLwT",
        "outputId": "c721e453-1027-4f9c-822b-40e50d726095"
      },
      "source": [
        "for obj in gc.get_objects():\n",
        "    try:\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
        "            print(type(obj), obj.size())\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: astor.all_symbols is deprecated.  Please use astor.symbol_data.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: astor.treewalk is deprecated.  Please use astor.tree_walk.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: astor.codegen is deprecated.  Please use astor.code_gen.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py:151: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32000, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([13, 1])\n",
            "<class 'torch.Tensor'> torch.Size([1, 512])\n",
            "<class 'torch.Tensor'> torch.Size([1, 512])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 39])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32000, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([512, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([13, 1])\n",
            "<class 'torch.Tensor'> torch.Size([1, 512])\n",
            "<class 'torch.Tensor'> torch.Size([1, 512])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([1, 39])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 7])\n",
            "<class 'torch.Tensor'> torch.Size([32])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 3072])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768, 768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150])\n",
            "<class 'torch.Tensor'> torch.Size([1, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 1, 1, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 150, 150])\n",
            "<class 'torch.Tensor'> torch.Size([32, 150, 3072])\n",
            "<class 'torch.Tensor'> torch.Size([32])\n",
            "<class 'torch.Tensor'> torch.Size([32])\n",
            "<class 'torch.Tensor'> torch.Size([])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 7])\n",
            "<class 'torch.Tensor'> torch.Size([32])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92])\n",
            "<class 'torch.Tensor'> torch.Size([1, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 1, 1, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 92, 92])\n",
            "<class 'torch.Tensor'> torch.Size([32, 92, 3072])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 3072])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 12, 235, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235, 768])\n",
            "<class 'torch.Tensor'> torch.Size([32, 1, 1, 235])\n",
            "<class 'torch.Tensor'> torch.Size([1, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32])\n",
            "<class 'torch.Tensor'> torch.Size([32, 7])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235])\n",
            "<class 'torch.Tensor'> torch.Size([32, 235])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 64])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 64])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 64])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 12, 512, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512, 768])\n",
            "<class 'torch.Tensor'> torch.Size([64, 1, 1, 512])\n",
            "<class 'torch.Tensor'> torch.Size([1, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64])\n",
            "<class 'torch.Tensor'> torch.Size([64, 7])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512])\n",
            "<class 'torch.Tensor'> torch.Size([64, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ezJVNBRShH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}